[
  {
    "slug": "auditflow-complete-audit-toolkit",
    "title": "AuditFlow - Complete Audit Toolkit Suite",
    "short_description": "A comprehensive suite of 8 specialized tools to streamline and automate end-to-end UIF COVID TERS audit workflows, cutting cycle times by up to 75%.",
    "featured": true,
    "cover_image": "images/projects/auditflow-suite.jpg",
    "gallery": [
      "images/projects/auditflow-suite.jpg",
      "images/projects/auditflow-1.png",
      "images/projects/auditflow-2.png",
      "images/projects/auditflow-3.png",
      "images/projects/auditflow-4.png",
      "images/projects/auditflow-5.png",
      "images/projects/auditflow-6.png"
    ],
    "tech_stack": [
      "python",
      "streamlit",
      "pandas",
      "sqlite"
    ],
    "tags": [
      "automation",
      "audit",
      "compliance",
      "internal-tools",
      "data-processing"
    ],
    "why_built": "Existing audit workflows, particularly for UIF COVID TERS, were slow, manually intensive, and error-prone. The suite was built to eliminate manual bottlenecks, improve reliability, and ensure full regulatory compliance for complex audit processes.",
    "development_approach": [
      "Developed 8 specialized tools to cover all aspects of the audit workflow, including communication (Email/Calls tracking), documentation (Working Papers/Reports), and analytics.",
      "Utilized Python and Streamlit to build robust data processing pipelines and interactive UI/dashboards, such as the Audit Report Generator.",
      "Implemented automated processes for data consolidation (Weekly Register Populator) and file handling (File Finder & Copier).",
      "Integrated IMAP sync and SQLite metrics for real-time tracking of email volumes and performance."
    ],
    "challenges": [
      {
        "challenge": "Integrating multiple distinct audit steps into a seamless workflow.",
        "solution": "Designed an integrated suite of 8 tools (Working Paper Generator, Email Tracker, etc.) that work together for complete workflow coverage."
      },
      {
        "challenge": "Achieving high-speed processing for complex, multi-source audit data.",
        "solution": "Built tools to process workflows 10x faster and reduce audit cycle times by using efficient, automated methods."
      }
    ],
    "outcomes": [
      "Reduced audit cycle times and manual effort by up to 75%.",
      "Achieved an estimated saving of 50+ hours per week for audit teams.",
      "Improved report quality and ensured 100% compliance with built-in checks and audit trails."
    ],
    "metrics": [
      "75% reduction in audit cycle time",
      "99% accuracy rate",
      "50+ hours saved per week"
    ],
    "repo_url": "#",
    "live_url": "https://peakdesignteam.github.io/audit_flow/",
    "video_url": "#"
  },
  {
    "slug": "uniexplorer",
    "title": "UniExplorer: University Program Aggregator & Eligibility Calculator",
    "short_description": "Developed a Next.js (App Router) and SQLite platform to aggregate 500+ South African university programs, offering real-time APS score calculation and personalized eligibility recommendations.",
    "featured": true,
    "cover_image": "images/projects/uniexplorer.jpg",
    "gallery": [
      "images/projects/uniexplorer.jpg"
    ],
    "tech_stack": [
      "nextjs 14 (app router)",
      "react 18",
      "typescript",
      "tailwindcss",
      "sqlite",
      "python",
      "server actions",
      "data modeling"
    ],
    "tags": [
      "full-stack",
      "data-aggregation",
      "education-tech",
      "nextjs",
      "recommendation-engine",
      "etl-pipeline",
      "supabase"
    ],
    "why_built": "Addressed the problem of **information fragmentation** in tertiary education by consolidating scattered university prospectus data (admission requirements, fees, deadlines) into a single, intelligent platform to streamline student decision-making.",
    "development_approach": [
      "Architecture: Built a modern **Next.js 14 App Router** application, leveraging **Server Actions** for efficient data fetching and mutations, ensuring performance through server-side rendering.",
      "Data Logic: Implemented a proprietary **Eligibility Checker** that calculates a student's **APS (Admission Point Score)** in real-time against granular program requirements (subjects, minimum scores, levels) stored in a normalized **SQLite database** (currently in development).",
      "Frontend Engineering: Utilized **TypeScript** and **TailwindCSS** to create a responsive, mobile-first UI with shared state management via **React Context** (e.g., EligibilityProvider).",
      "Database Design: Designed a **normalized relational schema** (universities, programmes, subjects, careers, program_subjects) to manage complex, inter-related eligibility criteria with high data integrity.",
      "Scalability: Migrating to **Supabase PostgreSQL** for production-grade scalability and implementing **Supabase Auth** for secure user authentication and saved preferences.",
      "Data Pipeline (Planned): Developing an automated **ETL pipeline** using Python to extract program data from university PDF prospectuses, transform it into structured records, and load it into the Supabase database for continuous data updates."
    ],
    "challenges": [
      {
        "challenge": "Consolidating Ambiguous and Fragmented Program Requirements",
        "solution": "**Normalized all admission criteria** (APS, subject prerequisites) into structured, queryable data fields within the database, providing **transparency in scoring** and clear fit explanations to the user."
      },
      {
        "challenge": "Maintaining Application Responsiveness with Complex Filtering",
        "solution": "Optimized data flow by using Next.js **Server Actions** for database queries, minimizing client-side load and ensuring rapid display of filtered results from the 500+ program database."
      }
    ],
    "outcomes": [
      "Delivered a **single source of truth** for South African tertiary education information.",
      "Enabled students to get personalized eligibility feedback and narrow their search options by **~70%** on average.",
      "Provided clear, data-driven explanations for qualification status, replacing eligibility confusion with certainty."
    ],
    "metrics": [
      "Achieved **~70% average search narrowing** through personalized eligibility filtering.",
      "Database contains **500+** university program records and their associated subject requirements."
    ],
    "repo_url": "YOUR_GITHUB_LINK_HERE",
    "live_url": "YOUR_LIVE_DEMO_LINK_HERE",
    "video_url": "#"
  },
  {
    "slug": "digital-farmers-tomato-disease-detection",
    "title": "Digital Farmers: Tomato Disease Detection Tool",
    "short_description": "AI-powered web application that instantly diagnoses tomato leaf diseases from uploaded images using a CNN model trained on 14,529+ images. Identifies 10 disease classes with confidence scores and provides treatment recommendations.",
    "featured": true,
    "cover_image": "images/projects/digital-farmers-1.png",
    "gallery": [
      "images/projects/digital-farmers-1.png",
      "images/projects/digital-farmers.png",
      "images/projects/digital-farmers-2.png",
      "images/projects/digital-farmers-3.png"
    ],
    "tech_stack": [
      "tensorflow",
      "keras",
      "fastapi",
      "python",
      "vanilla javascript",
      "html5/css3",
      "docker",
      "kubernetes",
      "nginx"
    ],
    "tags": [
      "computer-vision",
      "deep-learning",
      "agri-tech",
      "image-classification",
      "rest-api",
      "containerization",
      "healthcare"
    ],
    "why_built": "Agricultural disease detection is typically slow, requires expert knowledge, and is inaccessible to small-scale farmers. This tool was built to democratize plant disease diagnosis by providing instant, accurate AI-powered identification accessible via a simple web interface.",
    "development_approach": [
      "Model Architecture: Designed and trained a Convolutional Neural Network (CNN) using TensorFlow/Keras on the PlantVillage dataset (14,529 images across 10 tomato disease classes).",
      "Deep Learning Pipeline: Implemented data augmentation (random flip/rotation), normalization, and a 5-layer CNN architecture achieving 95%+ accuracy on the test set.",
      "API Development: Built a production-ready REST API using FastAPI with image preprocessing, model inference, and JSON response formatting for seamless frontend integration.",
      "Frontend Engineering: Created a responsive single-page application using vanilla JavaScript with drag-and-drop image upload, real-time prediction display, and detailed disease information modals.",
      "Containerization & Deployment: Dockerized both frontend (Nginx) and backend (Uvicorn) services, created Kubernetes manifests for orchestrated deployment, and implemented CI/CD pipelines."
    ],
    "challenges": [
      {
        "challenge": "Achieving High Model Accuracy Across Visually Similar Disease Classes",
        "solution": "Implemented robust data augmentation techniques and trained a deep 5-layer CNN architecture with carefully tuned hyperparameters (Adam optimizer, 25 epochs) to distinguish between similar diseases like Early Blight and Late Blight."
      },
      {
        "challenge": "Ensuring Fast Inference and User Experience",
        "solution": "Optimized the model for production by using TensorFlow SavedModel format, implemented efficient image preprocessing pipelines, and deployed on FastAPI for sub-second prediction times."
      }
    ],
    "outcomes": [
      "Delivered a fully functional AI-powered diagnostic tool accessible to farmers with minimal technical knowledge.",
      "Achieved 95%+ accuracy on disease classification with confidence scoring for transparency.",
      "Provided actionable treatment recommendations for each identified disease, enabling immediate farmer response."
    ],
    "metrics": [
      "95%+ model accuracy on test dataset",
      "Sub-second prediction response time",
      "10 disease classes identified (9 diseases + healthy)",
      "Trained on 14,529 labeled images"
    ],
    "repo_url": "https://github.com/sewardrichard/tomato-leave-disease-detection",
    "live_url": "https://sewardrichard.github.io/tomato-leave-disease-detection/",
    "video_url": "#"
  },
  {
    "slug": "memeber-data-manager",
    "title": "Project Y - Member Data Manager",
    "short_description": "Engineered a secure, cloud-native Power Platform solution on Azure SQL to replace manual processes, managing the full member lifecycle and providing real-time Business Intelligence via Power BI.",
    "featured": false,
    "cover_image": "images/projects/member-data-manager.jpg",
    "gallery": [
      "images/projects/member-data-manager.jpg"
    ],
    "tech_stack": [
      "azure sql",
      "power apps",
      "power bi",
      "python (pandas, sqlalchemy)",
      "git/github",
      "agile/scrum"
    ],
    "tags": [
      "data-engineering",
      "cloud-architecture",
      "low-code-development",
      "business-intelligence",
      "database-management"
    ],
    "why_built": "Migrated Project Y operations off decentralized spreadsheets, which caused critical data redundancy, version control issues, and data silos. The goal was to establish a secure, centralized Single Source of Truth for all program data.",
    "development_approach": [
      "Data Modeling: Designed a **normalized relational schema in Azure SQL** to ensure high data integrity and support complex relationships (Members, Teams, Projects).",
      "Data Engineering (ETL): Developed robust **Python ETL scripts** using **pandas** for data cleaning and **SQLAlchemy** for automated data ingestion and transformation, ensuring data consistency for analytics.",
      "Application Development: Built a secure **Power Apps Canvas App** frontend to implement full **CRUD** (Create, Read, Update, Delete) functionality for administrators across the member lifecycle.",
      "Business Intelligence: Created **Power BI Dashboards** to visualize key operational KPIs (e.g., project scoring, career track progress) for **real-time, data-driven decision-making**.",
      "Agile & Version Control: Utilized **Agile methodologies** (one-week sprints) and **Git/GitHub** for version control, including managing database scripts and Power Platform solution files (.msapp)."
    ],
    "challenges": [
      {
        "challenge": "Data Silos and Inconsistent Schemas",
        "solution": "Enforced a **unified ingestion strategy** with documented schemas and lineage, ensuring all member events are standardized and loaded into the normalized Azure SQL database."
      },
      {
        "challenge": "Managing Secure Database Access for Development Team",
        "solution": "Implemented rigorous **Azure SQL firewall configuration** and **IP whitelisting** to securely manage multi-user access to the PaaS database instance."
      }
    ],
    "outcomes": [
      "Established a **centralized, secure, and single source of truth** for all program data.",
      "**Significantly reduced administrative data entry time** and eliminated manual spreadsheet processes.",
      "Provided **real-time visibility** into program performance, reducing reporting turnaround time to **same-day** updates."
    ],
    "metrics": [
      "Reduced report turnaround time from several days to same-day (near real-time).",
      "100% elimination of critical data redundancy and version control issues.",
      "Enabled full-lifecycle tracking across enrollment, team assignment, and progress scoring."
    ],
    "repo_url": "YOUR_GITHUB_LINK_HERE",
    "live_url": "#",
    "video_url": "#"
  },
  {
    "slug": "ai-car-inspector",
    "title": "AI Car Inspector: Containerized Vision API & MLOps Deployment on AWS EKS",
    "short_description": "Architected, containerized, and deployed a Python/Gradio web application that uses **Google's Gemini 2.0 Flash** Vision API for two-stage vehicle identification, quality assessment, and attribute extraction, orchestrated via Kubernetes.",
    "featured": false,
    "cover_image": "images/projects/ai-car-inspector.jpg",
    "gallery": [
      "images/projects/ai-car-inspector.jpg"
    ],
    "tech_stack": [
      "python 3.11",
      "vision api (gemini 2.0 flash)",
      "docker",
      "kubernetes (eks)",
      "aws",
      "github actions",
      "gradio"
    ],
    "tags": [
      "mlops",
      "devops",
      "containerization",
      "generative-ai",
      "cloud-deployment",
      "vision-ai"
    ],
    "why_built": "Automate the time-consuming and inconsistent process of **manual vehicle inspection and data entry** at dealerships or auction sites. The goal was to provide a fast, standardized, and reliable digital alternative.",
    "development_approach": [
      "AI Engineering: Integrated the **Gemini 2.0 Flash** vision model to perform a two-stage analysis: 1) Image verification (car/not car) and 2) Structured extraction of attributes (make, model, year, condition, color).",
      "Containerization & CI/CD: Containerized the Python application using **Docker** and built an automated **CI/CD pipeline** via **GitHub Actions** for image building, pushing to a registry, and zero-downtime deployment.",
      "Cloud & Orchestration: Deployed the microservice to **AWS** using a **Kubernetes (EKS)** cluster. Wrote production-ready `deployment.yaml` and `service.yaml` to manage autoscaling and reliable service delivery.",
      "Interface: Developed a simple, user-friendly UI using **Gradio** for immediate visualization of the AI-extracted data."
    ],
    "challenges": [
      {
        "challenge": "Maintaining Vision Model Accuracy Across Diverse Photography Conditions",
        "solution": "Implemented strict **confidence thresholds** on the Vision API output and developed **fallback heuristics** to handle variable lighting, angles, or non-car images, ensuring data reliability."
      },
      {
        "challenge": "Orchestrating Containerized Services on Cloud Infrastructure",
        "solution": "Successfully deployed the image using **Kubernetes manifests** on AWS EKS, configuring load balancing and network security (e.g., secrets, firewalls) to ensure the service was externally accessible and stable."
      }
    ],
    "outcomes": [
      "Established a fully automated MLOps pipeline, demonstrating expertise in production-ready AI application delivery.",
      "Provided fast, accurate, and standardized data extraction for car inspection.",
      "Achieved a highly available and scalable solution using Kubernetes orchestration."
    ],
    "metrics": [
      "Achieved an estimated **~50% reduction in manual inspection steps** by automating initial data capture.",
      "Implemented a CI/CD pipeline leading to **zero failed deployments** during the final sprint phase.",
      "Successfully integrated and deployed the application using **Python 3.11, Docker, and AWS EKS**."
    ],
    "repo_url": "https://github.com/dev-api-org/ai-app-containerization",
    "live_url": "#",
    "video_url": "#"
  }
]
